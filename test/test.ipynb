{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jianghao/Code/Graduation/CompressAI/examples/assets/stmalo_fracape.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     16\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 17\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jianghao/Code/Graduation/CompressAI/examples/assets/stmalo_fracape.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToTensor()(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2950\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 2953\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2954\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jianghao/Code/Graduation/CompressAI/examples/assets/stmalo_fracape.png'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "def _compute_psnr(a, b, max_val: float = 1.0) -> float:\n",
    "    mse = torch.mean((a - b) ** 2).item()\n",
    "    psnr = 20 * np.log10(max_val) - 10 * np.log10(mse)\n",
    "    return psnr\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "img = Image.open('./stmalo_fracape.png').convert('RGB')\n",
    "x = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "\n",
    "theta = torch.rand(1).unsqueeze(0).to(device)\n",
    "theta = theta * 0.5 + 0.5\n",
    "# theta = torch.tensor(0.9607).to(device)\n",
    "# theta = tehta.reshape(1,1)\n",
    "# theta = torch.ones((1,1)).to(device)\n",
    "theta0 = torch.zeros_like(theta, dtype=torch.float32).to(device)\n",
    "print(theta)\n",
    "stn_matrix = torch.cat((1/theta, theta0, theta0, theta0, 1/theta, theta0), axis=1)\n",
    "stn_revmatrix = torch.cat((theta, theta0, theta0, theta0, theta, theta0), axis=1)\n",
    "\n",
    "B, C, H, W = x.shape\n",
    "rh = torch.full(theta.size(), H, dtype=torch.int32).to(device)\n",
    "rw = torch.full(theta.size(), W, dtype=torch.int32).to(device)\n",
    "ch = torch.minimum(torch.floor(H * theta + 4).to(torch.int32).to(device), rh)\n",
    "cw = torch.minimum(torch.floor(W * theta + 4).to(torch.int32).to(device), rw)\n",
    "ph1 = ((rh - ch) / 2).to(torch.int32)\n",
    "ph2 = (rh - ch - ph1).to(torch.int32)\n",
    "pw1 = ((rw - cw) / 2).to(torch.int32)\n",
    "pw2 = (rw - cw - pw1).to(torch.int32)\n",
    "\n",
    "grid = F.affine_grid(stn_matrix.view(1, 2, 3), x.size())\n",
    "grid1 = F.affine_grid(stn_matrix.view(1,2,3), [B, C, ch, cw])\n",
    "\n",
    "y = F.grid_sample(x, grid, mode='bicubic')\n",
    "if ph2 > 0 and pw2 > 0:\n",
    "    z = y[:, :, ph1:-ph2, pw1:-pw2]\n",
    "    z = F.pad(z, (pw1, pw2, ph1, ph2))\n",
    "else:\n",
    "    z = y\n",
    "grid_rev = F.affine_grid(stn_revmatrix.view(1, 2, 3), z.size())\n",
    "\n",
    "w = F.grid_sample(z, grid_rev, mode='bicubic')\n",
    "w1 = F.grid_sample(y, grid_rev, mode='bicubic')\n",
    "\n",
    "y1 = F.grid_sample(x, grid1, mode='bicubic')\n",
    "grid1_rev = F.affine_grid(stn_revmatrix.view(1, 2, 3), z.size())\n",
    "w2 = F.grid_sample(y1, grid1_rev, mode='bicubic')\n",
    "\n",
    "\n",
    "print(y1.size())\n",
    "print(z.size())\n",
    "print('psnr %f'%(_compute_psnr(x, w)))\n",
    "print('psnr %f'%(_compute_psnr(x, w1)))\n",
    "print('psnr %f'%(_compute_psnr(x, w2)))\n",
    "\n",
    "\n",
    "y = transforms.ToPILImage()(y.squeeze().cpu())\n",
    "z = transforms.ToPILImage()(z.squeeze().cpu())\n",
    "w = transforms.ToPILImage()(w.squeeze().cpu())\n",
    "# w2 = transforms.ToPILImage()(w2.squeeze().cpu())\n",
    "b = F.interpolate(x, (int(H * theta), int(W * theta)), mode='bicubic')\n",
    "c = F.interpolate(b, (H, W), mode='bicubic')\n",
    "print('psnr %f'%(_compute_psnr(x, c)))\n",
    "c = transforms.ToPILImage()(c.squeeze().cpu())\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.axis('off')\n",
    "plt.imshow(transforms.ToPILImage()(y1.squeeze().cpu()))\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.axis('off')\n",
    "plt.imshow(transforms.ToPILImage()(w2.squeeze().cpu()))\n",
    "plt.show()\n",
    "\n",
    "# w2 = F.interpolate(y[:, :, ph1:-ph2, pw1:-pw2], (H, W), mode='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdc1a8ff30b159d2c5f5500eceb57a31b5d420938a114ff29ae49076af09b850"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
